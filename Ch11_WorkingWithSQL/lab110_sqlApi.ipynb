{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/gani/spark-2.4.4-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('geo',StringType(), True),\n",
    "    StructField('yr1980', DoubleType(), False),\n",
    "    StructField('yr1981', DoubleType(), False),\n",
    "    StructField('yr1982', DoubleType(), False),\n",
    "    StructField('yr1983', DoubleType(), False),\n",
    "    StructField('yr1984', DoubleType(), False),\n",
    "    StructField('yr1985', DoubleType(), False),\n",
    "    StructField('yr1986', DoubleType(), False),\n",
    "    StructField('yr1987', DoubleType(), False),\n",
    "    StructField('yr1988', DoubleType(), False),\n",
    "    StructField('yr1989', DoubleType(), False),\n",
    "    StructField('yr1990', DoubleType(), False),\n",
    "    StructField('yr1991', DoubleType(), False),\n",
    "    StructField('yr1992', DoubleType(), False),\n",
    "    StructField('yr1993', DoubleType(), False),\n",
    "    StructField('yr1994', DoubleType(), False),\n",
    "    StructField('yr1995', DoubleType(), False),\n",
    "    StructField('yr1996', DoubleType(), False),\n",
    "    StructField('yr1997', DoubleType(), False),\n",
    "    StructField('yr1998', DoubleType(), False),\n",
    "    StructField('yr1999', DoubleType(), False),\n",
    "    StructField('yr2000', DoubleType(), False),\n",
    "    StructField('yr2001', DoubleType(), False),\n",
    "    StructField('yr2002', DoubleType(), False),\n",
    "    StructField('yr2003', DoubleType(), False),\n",
    "    StructField('yr2004', DoubleType(), False),\n",
    "    StructField('yr2005', DoubleType(), False),\n",
    "    StructField('yr2006', DoubleType(), False),\n",
    "    StructField('yr2007', DoubleType(), False),\n",
    "    StructField('yr2008', DoubleType(), False),\n",
    "    StructField('yr2009', DoubleType(), False),\n",
    "    StructField('yr2010', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('sqlApp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('populationbycountry19802010millions.csv', inferSchema=True, header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1981,2010):\n",
    "    df = df.drop(F.col('yr{}'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------+\n",
      "|          geo|   yr1980|   yr2010|\n",
      "+-------------+---------+---------+\n",
      "|North America|320.27638|456.59331|\n",
      "|      Bermuda|  0.05473|  0.06827|\n",
      "|       Canada|  24.5933| 33.75974|\n",
      "|    Greenland|  0.05021|  0.05764|\n",
      "|       Mexico| 68.34748|112.46886|\n",
      "+-------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('evolution',F.expr('round((yr2010 - yr1980) * 1000000)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------+-----------+\n",
      "|          geo|   yr1980|   yr2010|  evolution|\n",
      "+-------------+---------+---------+-----------+\n",
      "|North America|320.27638|456.59331|1.3631693E8|\n",
      "|      Bermuda|  0.05473|  0.06827|    13540.0|\n",
      "|       Canada|  24.5933| 33.75974|  9166440.0|\n",
      "|    Greenland|  0.05021|  0.05764|     7430.0|\n",
      "|       Mexico| 68.34748|112.46886| 4.412138E7|\n",
      "+-------------+---------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('geodata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"\n",
    "        select * from geodata\n",
    "        where geo is not null and evolution <= 0\n",
    "        order by evolution\n",
    "        limit 25\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeEvo = spark.sql(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-------+---------+\n",
      "|                 geo| yr1980| yr2010|evolution|\n",
      "+--------------------+-------+-------+---------+\n",
      "|Saint Pierre and ...|0.00599|0.00594|    -50.0|\n",
      "|            Dominica|0.07389|0.07281|  -1080.0|\n",
      "|Netherlands Antilles|0.23244|0.22869|  -3750.0|\n",
      "|        Cook Islands|0.01801|0.01149|  -6520.0|\n",
      "|          Montserrat|0.01177|0.00512|  -6650.0|\n",
      "+--------------------+-------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "negativeEvo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "        select * from geodata\n",
    "        where geo is not null and evolution > 999999\n",
    "        order by evolution desc\n",
    "        limit 25\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "moreThanMill = spark.sql(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------+------------+\n",
      "|           geo|    yr1980|    yr2010|   evolution|\n",
      "+--------------+----------+----------+------------+\n",
      "|         World|4451.32679|6853.01941|2.40169262E9|\n",
      "|Asia & Oceania|2469.81743|3799.67028|1.32985285E9|\n",
      "|        Africa| 478.96479|1015.47842| 5.3651363E8|\n",
      "|         India|  684.8877|1173.10802| 4.8822032E8|\n",
      "|         China| 984.73646|1330.14129| 3.4540483E8|\n",
      "+--------------+----------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moreThanMill.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
